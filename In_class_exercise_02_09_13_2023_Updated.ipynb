{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greeshmanth-5/Greeshmanth_INFO5731_Fall2023/blob/main/In_class_exercise_02_09_13_2023_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW5_oFVd9-pY"
      },
      "source": [
        "## The second In-class-exercise (09/13/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kindly use the provided .ipynb document to write your code or respond to the questions. Avoid generating a new file.\n",
        "Execute all the cells before your final submission."
      ],
      "metadata": {
        "id": "mAzh1U0sE5I5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This in-class exercise is due tomorrow September 14, 2023 at 11:59 PM. No late submissions will be considered."
      ],
      "metadata": {
        "id": "PpgvZQdRE-HV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QBZI-je9-pZ"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWoKpYQT9-pa"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Research Question:**\n",
        "\n",
        "\"Who are the top all-time wicket-takers in cricket, and how do their performances correlate with their team's victories?\"\n",
        "\n",
        "For this question, data can be collected from the same sources you mentioned, like ESPN or Cricinfo. The fields you'd be interested in could include:\n",
        "\n",
        "Bowling style (e.g., spin, fast, medium-paced)\n",
        "\n",
        "Number of matches played\n",
        "\n",
        "Total wickets taken\n",
        "\n",
        "Average runs given per wicket\n",
        "\n",
        "Number of 5-wicket hauls\n",
        "\n",
        "Number of 10-wicket hauls (in a match)\n",
        "\n",
        "**Steps to Gather Data:**\n",
        "\n",
        "\n",
        "\n",
        "1.   Loop through the different pages\n",
        "2.   Send HTTP requests\n",
        "\n",
        "3.   Parse the HTML content\n",
        "4.   Store relevant data\n",
        "\n",
        "1.  Loop through each bowler's information\n",
        "2.   Convert to structured data format\n",
        "\n",
        "7.   Print/save the DataFrame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "blnHOrBjQ_IT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "00jrL1j1Q4jM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlxTLRNm9-pa"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "QpWOgjHi9-pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28bbc5f9-78a6-4a8e-8121-a46decef7cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data scraping completed and saved to top_bowlers_data.csv\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px6wgvog9-pa"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2013-2023).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "class SemanticScholarAPI:\n",
        "\n",
        "    BASE_URL = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "\n",
        "    def fetch_data(self, topic, offset=0, limit=10):\n",
        "        params = {\n",
        "            \"query\": topic,\n",
        "            \"offset\": offset,\n",
        "            \"limit\": limit,\n",
        "            \"fields\": \"url,title,abstract,authors\"\n",
        "        }\n",
        "        response = self.session.get(self.BASE_URL, params=params)\n",
        "        response.raise_for_status()\n",
        "        return response.json()['data']\n",
        "\n",
        "def main():\n",
        "    api = SemanticScholarAPI()\n",
        "    topic = 'Money'\n",
        "\n",
        "    try:\n",
        "        data = api.fetch_data(topic, offset=100, limit=3)\n",
        "        df = pd.DataFrame(data)\n",
        "        print(df.head(1000))\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching data for topic {topic}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-PYXE8QJgy2",
        "outputId": "f2e09b83-39ba-49e0-cb88-83bf4100b6fd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    paperId  \\\n",
            "0  ff279098481a87faa4498fa9088cd9bd835e9a3e   \n",
            "1  b2c827333b780d4f76b56c6e90bb9141dc31278f   \n",
            "2  ac0182df6bbf38fb68911309ff729d9edb24c8b0   \n",
            "\n",
            "                                                 url  \\\n",
            "0  https://www.semanticscholar.org/paper/ff279098...   \n",
            "1  https://www.semanticscholar.org/paper/b2c82733...   \n",
            "2  https://www.semanticscholar.org/paper/ac0182df...   \n",
            "\n",
            "                                               title  \\\n",
            "0  More than fun and money. Worker Motivation in ...   \n",
            "1  Money and Thinking: Reminders of Money Trigger...   \n",
            "2  ‘Bridges to cash’ : Channelling agency in mobi...   \n",
            "\n",
            "                                            abstract  \\\n",
            "0  The payment in paid crowdsourcing markets like...   \n",
            "1  The idea of money reminds consumers of persona...   \n",
            "2  Encountered by mobile money professionals - in...   \n",
            "\n",
            "                                             authors  \n",
            "0  [{'authorId': '2563486', 'name': 'Nicolas Kauf...  \n",
            "1  [{'authorId': '49419254', 'name': 'Jochim Hans...  \n",
            "2  [{'authorId': '40210117', 'name': 'B. Maurer'}...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do either of the question-4 tasks given below."
      ],
      "metadata": {
        "id": "yCQpbJnwTxAB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT3CNj_V9-pb"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data.\n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FymVNKVi9-pb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4 (10 points):\n",
        "\n",
        "In this task, you are required to identify and utilize online tools for web scraping data from websites without the need for coding, with a specific focus on Parsehub. The objective is to gather data and save it in formats like CSV, Excel, or any other suitable file format.\n",
        "\n",
        "You have to mention an introduction to the tool which ever you prefer to use, steps to follow for web scrapping and the final output of the data collected.\n",
        "\n",
        "Upload a document (Word or PDF File) in the same repository and you can add the link in the ipynb file."
      ],
      "metadata": {
        "id": "wOeAr9TJTBgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the link to the document here\n",
        "https://github.com/greeshmanth-5/Greeshmanth_INFO5731_Fall2023/blob/main/Introduction%20to%20ParseHub.docx.pdf"
      ],
      "metadata": {
        "id": "N20TjXLmTG1u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}